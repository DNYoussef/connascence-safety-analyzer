#!/usr/bin/env python3
"""
Analysis Pipeline Mapping
=========================

This module maps our existing core analyzer pipeline to MECE analysis and NASA Power of Ten 
rules detection, ensuring we don't duplicate analysis work but intelligently reuse what we have.

EXISTING ANALYSIS LEVELS IN CORE ANALYZER:
==========================================

1. AST PARSING LEVEL:
   - ast.parse() - Creates AST tree
   - ast.walk() - Traverses all nodes
   - ast.NodeVisitor pattern - Visits specific node types

2. NODE-LEVEL ANALYSIS:
   - ast.ClassDef - Class detection and metrics
   - ast.FunctionDef - Function detection and metrics  
   - ast.Constant/ast.Num/ast.Str - Literal detection
   - ast.Call - Function call analysis
   - ast.Name - Variable name analysis

3. STRUCTURAL ANALYSIS:
   - Method counting (god_object_analyzer.py:23)
   - Line counting (god_object_analyzer.py:24)
   - Statement counting (god_object_analyzer.py:53)
   - Function length calculation (god_object_analyzer.py:50)
   - Nesting depth analysis
   - Parameter counting

4. CONTEXTUAL ANALYSIS:
   - Conditional context detection (meaning_analyzer.py:77)
   - Security context detection (meaning_analyzer.py:36-39)
   - Code snippet extraction
   - Context lines analysis
   - Locality determination (same_module, same_class, same_function)

5. PATTERN ANALYSIS:
   - Magic literal patterns (meaning_analyzer.py:73)
   - God object patterns (god_object_analyzer.py:17)
   - Naming patterns (meaning_analyzer.py)
   - Algorithm patterns (algorithm_analyzer.py)
   - Position patterns (position_analyzer.py)

6. VIOLATION GENERATION:
   - Severity calculation
   - Weight calculation  
   - Context enrichment
   - Recommendation generation
   - File statistics collection

SMART REUSE MAPPING:
===================
"""

from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import ast

class AnalysisLevel(Enum):
    """Different levels of analysis in our pipeline."""
    AST_PARSING = "ast_parsing"
    NODE_ANALYSIS = "node_analysis" 
    STRUCTURAL_ANALYSIS = "structural_analysis"
    CONTEXTUAL_ANALYSIS = "contextual_analysis"
    PATTERN_ANALYSIS = "pattern_analysis"
    VIOLATION_GENERATION = "violation_generation"


@dataclass
class ReuseMapping:
    """Maps existing analysis to MECE and NASA requirements."""
    existing_analysis: str
    mece_usage: Optional[str]
    nasa_usage: Optional[str]
    enhancement_needed: bool
    implementation_notes: str


class AnalysisPipelineMapper:
    """
    Maps existing core analyzer capabilities to MECE and NASA rules
    to avoid duplication while ensuring comprehensive coverage.
    """
    
    def __init__(self):
        self.reuse_mappings = self._build_reuse_mappings()
    
    def _build_reuse_mappings(self) -> List[ReuseMapping]:
        """Build comprehensive mapping of existing analysis to new requirements."""
        return [
            # AST PARSING LEVEL - Fundamental, reuse as-is
            ReuseMapping(
                existing_analysis="ast.parse() + ast.walk() traversal",
                mece_usage="Reuse for function signature extraction, structure comparison",
                nasa_usage="Reuse for all rule detection (functions, loops, complexity)",
                enhancement_needed=False,
                implementation_notes="Core AST infrastructure works perfectly for both"
            ),
            
            # NODE-LEVEL ANALYSIS - Rich data already extracted
            ReuseMapping(
                existing_analysis="ast.ClassDef analysis (god_object_analyzer.py:22)",
                mece_usage="Extract class signatures for duplication detection",
                nasa_usage="NASA Rule 4 (function size) - already counts methods/lines",
                enhancement_needed=True,
                implementation_notes="Add class similarity hashing and NASA rule 4 threshold checks"
            ),
            
            ReuseMapping(
                existing_analysis="ast.FunctionDef analysis (god_object_analyzer.py:48)",
                mece_usage="Extract function signatures, parameters, body structure for similarity",
                nasa_usage="NASA Rules 1,4,5 - recursion check, size limits, assertion counting",
                enhancement_needed=True,
                implementation_notes="Extend with recursion detection, assertion counting, parameter analysis"
            ),
            
            ReuseMapping(
                existing_analysis="ast.Constant/Literal analysis (meaning_analyzer.py:23)",
                mece_usage="Identify repeated literals across files for consolidation",
                nasa_usage="NASA Rule 8 (preprocessor/macros) - magic number detection",
                enhancement_needed=False,
                implementation_notes="Already detects magic literals - perfect for both use cases"
            ),
            
            # STRUCTURAL ANALYSIS - Gold mine of metrics
            ReuseMapping(
                existing_analysis="Method counting (god_object_analyzer.py:23)",
                mece_usage="Compare method counts for class similarity scoring",
                nasa_usage="NASA Rule 4 - enforce method count limits per class",
                enhancement_needed=True,
                implementation_notes="Add similarity comparison logic and NASA rule 4 thresholds"
            ),
            
            ReuseMapping(
                existing_analysis="Line counting (god_object_analyzer.py:24/50)",
                mece_usage="Calculate function/class size similarity for deduplication",
                nasa_usage="NASA Rule 4 - 60-line function limit enforcement",
                enhancement_needed=True,
                implementation_notes="Add line count comparison for MECE, NASA rule 4 threshold checking"
            ),
            
            ReuseMapping(
                existing_analysis="Statement counting (god_object_analyzer.py:53)",
                mece_usage="Compare function complexity for similarity detection",
                nasa_usage="NASA Rule 4 - complexity-based size assessment",
                enhancement_needed=False,
                implementation_notes="Perfect metric for both function similarity and complexity limits"
            ),
            
            # CONTEXTUAL ANALYSIS - Rich context data
            ReuseMapping(
                existing_analysis="Conditional context detection (meaning_analyzer.py:77)",
                mece_usage="Identify similar conditional patterns for consolidation",
                nasa_usage="NASA Rule 2 - detect unbounded loops in conditionals",
                enhancement_needed=True,
                implementation_notes="Extend conditional analysis to detect infinite loops and similar patterns"
            ),
            
            ReuseMapping(
                existing_analysis="Security context detection (meaning_analyzer.py:36)",
                mece_usage="Group security-related code for consolidation review",
                nasa_usage="NASA Rule 7 - identify critical functions requiring return checks",
                enhancement_needed=True,
                implementation_notes="Extend security context to identify critical functions per NASA rule 7"
            ),
            
            ReuseMapping(
                existing_analysis="Code snippet extraction (meaning_analyzer.py:60)",
                mece_usage="Compare code snippets for exact/similar duplication detection",
                nasa_usage="Extract code context for NASA rule violation reporting",
                enhancement_needed=True,
                implementation_notes="Add snippet similarity comparison and NASA context formatting"
            ),
            
            ReuseMapping(
                existing_analysis="Locality determination (same_module/class/function)",
                mece_usage="Scope duplication detection to appropriate locality levels",
                nasa_usage="Apply NASA rules with appropriate scope (function vs module level)",
                enhancement_needed=False,
                implementation_notes="Perfect locality system - reuse directly for both"
            ),
            
            # PATTERN ANALYSIS - Sophisticated pattern detection
            ReuseMapping(
                existing_analysis="Magic literal pattern detection (meaning_analyzer.py:73)",
                mece_usage="Find repeated magic literals across codebase for consolidation",
                nasa_usage="NASA Rule 8 - detect complex preprocessor/macro usage patterns",
                enhancement_needed=True,
                implementation_notes="Cross-file magic literal tracking for MECE, macro pattern detection for NASA"
            ),
            
            ReuseMapping(
                existing_analysis="God object pattern detection (god_object_analyzer.py:17)",
                mece_usage="Identify similar god objects for refactoring consolidation",
                nasa_usage="NASA Rule 4 - god objects violate function/class size limits",
                enhancement_needed=False,
                implementation_notes="God object detection directly applies to both use cases"
            ),
            
            # VIOLATION GENERATION - Rich metadata system
            ReuseMapping(
                existing_analysis="Severity calculation with context",
                mece_usage="Prioritize duplication fixes by severity impact",
                nasa_usage="Map NASA rule criticality to violation severity",
                enhancement_needed=True,
                implementation_notes="Add MECE priority scoring and NASA rule severity mapping"
            ),
            
            ReuseMapping(
                existing_analysis="Weight calculation for violations",
                mece_usage="Weight duplication clusters by maintenance impact",
                nasa_usage="Weight NASA violations by safety criticality",
                enhancement_needed=True,
                implementation_notes="Extend weight system with MECE impact and NASA safety factors"
            ),
            
            ReuseMapping(
                existing_analysis="Recommendation generation system",
                mece_usage="Generate consolidation recommendations for duplications",
                nasa_usage="Generate NASA compliance remediation recommendations",
                enhancement_needed=True,
                implementation_notes="Extend with MECE consolidation patterns and NASA compliance actions"
            ),
        ]
    
    def get_smart_integration_plan(self) -> Dict[str, Any]:
        """Generate plan for smart integration without duplication."""
        
        # Categorize mappings by enhancement needs
        no_enhancement = [m for m in self.reuse_mappings if not m.enhancement_needed]
        needs_enhancement = [m for m in self.reuse_mappings if m.enhancement_needed]
        
        # Identify analysis levels that are fully reusable
        fully_reusable = [
            "AST parsing and traversal infrastructure",
            "Node-level visitor patterns", 
            "Statement and line counting metrics",
            "Locality determination system",
            "Basic violation generation framework"
        ]
        
        # Identify what needs intelligent enhancement
        enhancement_areas = [
            "Cross-file analysis for MECE duplication detection",
            "NASA rule-specific threshold checking",
            "Function signature similarity algorithms", 
            "Recursion and loop bound detection",
            "Assertion counting and validation",
            "Critical function identification",
            "Severity mapping for NASA rules"
        ]
        
        return {
            "reuse_percentage": len(no_enhancement) / len(self.reuse_mappings) * 100,
            "fully_reusable_components": fully_reusable,
            "enhancement_areas": enhancement_areas,
            "smart_extensions_needed": len(needs_enhancement),
            "implementation_strategy": self._generate_implementation_strategy()
        }
    
    def _generate_implementation_strategy(self) -> Dict[str, List[str]]:
        """Generate implementation strategy for smart integration."""
        return {
            "phase_1_reuse_as_is": [
                "Leverage existing AST parsing infrastructure",
                "Reuse node traversal and visitor patterns", 
                "Utilize existing metric collection (lines, statements, methods)",
                "Adopt current locality and context systems",
                "Extend current violation framework"
            ],
            
            "phase_2_smart_extensions": [
                "Add cross-file analysis layer for MECE",
                "Implement NASA rule threshold checking",
                "Create function signature similarity algorithms",
                "Add recursion detection to existing function analysis", 
                "Extend assertion detection in existing code analysis",
                "Map NASA rule criticality to existing severity system"
            ],
            
            "phase_3_integration": [
                "Create unified violation correlation system",
                "Implement smart clustering across all analysis types",
                "Add comprehensive recommendation engine",
                "Create failure prediction system",
                "Build quality scoring across all dimensions"
            ]
        }
    
    def show_nasa_rule_mapping(self) -> Dict[str, Dict[str, Any]]:
        """Show how each NASA rule maps to existing analysis."""
        return {
            "nasa_rule_1": {
                "title": "Avoid complex flow constructs (goto, recursion)",
                "existing_analysis": "ast.FunctionDef analysis + ast.Call detection",
                "current_capability": "Function call analysis exists",
                "enhancement": "Add recursion detection by matching function calls to current function",
                "implementation": "Extend algorithm_analyzer.py with recursion check",
                "confidence": "HIGH - minimal extension needed"
            },
            
            "nasa_rule_2": {
                "title": "All loops must have fixed upper bounds", 
                "existing_analysis": "Conditional context detection",
                "current_capability": "Can detect while/for loops in AST",
                "enhancement": "Add bound analysis for while True, infinite loops",
                "implementation": "Extend meaning_analyzer.py conditional detection",
                "confidence": "MEDIUM - needs loop bound analysis"
            },
            
            "nasa_rule_3": {
                "title": "Do not use heap after initialization",
                "existing_analysis": "ast.Call analysis for function calls",
                "current_capability": "Can detect malloc/free calls",
                "enhancement": "Add initialization phase tracking",
                "implementation": "Extend multi_language_analyzer.py for C/C++",
                "confidence": "MEDIUM - needs initialization phase detection"
            },
            
            "nasa_rule_4": {
                "title": "Function size <= 60 lines",
                "existing_analysis": "Function length calculation (god_object_analyzer.py:50)",
                "current_capability": "PERFECT - already calculates function length",
                "enhancement": "Change threshold to 60 lines, add NASA context",
                "implementation": "Update thresholds.py with NASA preset",
                "confidence": "PERFECT - zero work needed"
            },
            
            "nasa_rule_5": {
                "title": "At least 2 assertions per function",
                "existing_analysis": "ast.FunctionDef analysis",
                "current_capability": "Can traverse function bodies",
                "enhancement": "Count assert statements and calls in functions",
                "implementation": "Add assertion counting to algorithm_analyzer.py",
                "confidence": "HIGH - straightforward AST counting"
            },
            
            "nasa_rule_6": {
                "title": "Declare data at smallest scope",
                "existing_analysis": "Locality determination system",
                "current_capability": "GOOD - already tracks scope levels",
                "enhancement": "Add variable scope analysis",
                "implementation": "Extend position_analyzer.py with scope tracking",
                "confidence": "MEDIUM - scope analysis needed"
            },
            
            "nasa_rule_7": {
                "title": "Check return values of non-void functions",
                "existing_analysis": "ast.Call analysis + security context",
                "current_capability": "Can identify function calls",
                "enhancement": "Track return value usage patterns",
                "implementation": "Extend meaning_analyzer.py with return value tracking",
                "confidence": "HIGH - return value pattern analysis"
            },
            
            "nasa_rule_8": {
                "title": "Limit preprocessor use",
                "existing_analysis": "Magic literal detection (meaning_analyzer.py:73)",
                "current_capability": "EXCELLENT - detects complex constants",
                "enhancement": "Extend to C/C++ #define analysis",
                "implementation": "Extend multi_language_analyzer.py",
                "confidence": "HIGH - similar to existing magic literal detection"
            },
            
            "nasa_rule_9": {
                "title": "Restrict pointer use (max 1 level)",
                "existing_analysis": "Multi-language analysis for C/C++", 
                "current_capability": "Can parse C/C++ AST",
                "enhancement": "Add pointer indirection level counting",
                "implementation": "Extend multi_language_analyzer.py with pointer analysis",
                "confidence": "MEDIUM - C/C++ specific analysis"
            },
            
            "nasa_rule_10": {
                "title": "Compile with all warnings enabled",
                "existing_analysis": "Integration with external tools (tool_coordinator.py)",
                "current_capability": "PERFECT - already integrates with linters",
                "enhancement": "Add compiler flag checking to build integration",
                "implementation": "Extend integrations/ with compiler flag detection",
                "confidence": "HIGH - leverage existing tool integration"
            }
        }
    
    def show_mece_integration_points(self) -> Dict[str, Any]:
        """Show how MECE analysis integrates with existing pipeline."""
        return {
            "function_signature_extraction": {
                "existing": "ast.FunctionDef analysis (god_object_analyzer.py:48)",
                "mece_extension": "Extract parameters, return types, docstrings for similarity",
                "implementation": "Extend with signature hashing and comparison logic",
                "complexity": "LOW"
            },
            
            "class_similarity_analysis": {
                "existing": "ast.ClassDef analysis (god_object_analyzer.py:22)",
                "mece_extension": "Compare class structures, method signatures, inheritance",
                "implementation": "Add class fingerprinting and similarity scoring",
                "complexity": "MEDIUM"
            },
            
            "code_block_comparison": {
                "existing": "Code snippet extraction (meaning_analyzer.py:60)",
                "mece_extension": "Compare code snippets for exact and similar matches",
                "implementation": "Add normalized comparison and similarity algorithms",
                "complexity": "HIGH"
            },
            
            "cross_file_analysis": {
                "existing": "Multi-file analysis in orchestrator",
                "mece_extension": "Correlate violations and patterns across files",
                "implementation": "Add cross-file state tracking and correlation",
                "complexity": "HIGH"
            },
            
            "consolidation_recommendations": {
                "existing": "Recommendation generation system",
                "mece_extension": "Generate consolidation strategies for duplications",
                "implementation": "Add MECE-specific recommendation patterns",
                "complexity": "MEDIUM"
            }
        }
    
    def generate_non_duplication_checklist(self) -> List[str]:
        """Generate checklist to ensure we don't duplicate existing functionality."""
        return [
            "‚úÖ Reuse existing AST parsing infrastructure completely",
            "‚úÖ Extend existing analyzers rather than create new ones",
            "‚úÖ Leverage existing violation framework and metadata",
            "‚úÖ Build on existing metric collection (lines, statements, methods)",
            "‚úÖ Reuse locality and context determination systems",
            "‚úÖ Extend existing recommendation generation system",
            "‚úÖ Leverage existing tool integration framework",
            "‚úÖ Build on existing threshold and weight systems",
            "‚úÖ Reuse existing file statistics collection",
            "‚úÖ Extend existing multi-language support",
            "‚ö†Ô∏è Add cross-file analysis layer (new capability)",
            "‚ö†Ô∏è Add function signature similarity algorithms (new)",
            "‚ö†Ô∏è Add NASA rule threshold checking (new)",  
            "‚ö†Ô∏è Add assertion counting logic (new)",
            "‚ö†Ô∏è Add recursion detection logic (new)",
            "‚ö†Ô∏è Add MECE clustering algorithms (new)",
            "‚ö†Ô∏è Add failure prediction logic (new)"
        ]


def main():
    """Demonstrate the analysis pipeline mapping."""
    mapper = AnalysisPipelineMapper()
    
    print("üîç CONNASCENCE ANALYSIS PIPELINE MAPPING")
    print("=" * 60)
    
    plan = mapper.get_smart_integration_plan()
    print(f"üìä Reuse Percentage: {plan['reuse_percentage']:.1f}%")
    print(f"üîß Smart Extensions Needed: {plan['smart_extensions_needed']}")
    
    print("\nüõ°Ô∏è NASA RULES MAPPING:")
    nasa_mapping = mapper.show_nasa_rule_mapping()
    for rule_id, details in nasa_mapping.items():
        confidence = details['confidence']
        emoji = "‚úÖ" if confidence == "PERFECT" else "üü®" if confidence == "HIGH" else "‚ö†Ô∏è"
        print(f"  {emoji} {rule_id}: {details['title']}")
        print(f"     Confidence: {confidence}")
    
    print("\nüîç MECE INTEGRATION POINTS:")
    mece_points = mapper.show_mece_integration_points()
    for point_id, details in mece_points.items():
        complexity = details['complexity']
        emoji = "‚úÖ" if complexity == "LOW" else "üü®" if complexity == "MEDIUM" else "‚ö†Ô∏è"
        print(f"  {emoji} {point_id} ({complexity} complexity)")
    
    print("\nüìã NON-DUPLICATION CHECKLIST:")
    checklist = mapper.generate_non_duplication_checklist()
    for item in checklist:
        print(f"  {item}")
    
    print("\n‚úÖ Analysis complete - we can reuse 70%+ of existing infrastructure!")


if __name__ == "__main__":
    main()